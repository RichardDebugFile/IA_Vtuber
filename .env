# ---- Otros servicios (tal cual los tienes) ----
GATEWAY_HTTP=http://127.0.0.1:8765
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_MODEL=gemma3

# ---- Fish Speech: rutas (ajusta si cambian) ----
FISH_REPO=G:\Documentos G\Ing. Sotware\ExperimentosPy\Fish-audio\fish-speech
FISH_VENV_PY=G:\Documentos G\Ing. Sotware\ExperimentosPy\Fish-audio\fish-speech\.fs\Scripts\python.exe
FISH_CKPT=G:\Documentos G\Ing. Sotware\ExperimentosPy\IA_VtuberMain\IA_Vtuber\services\tts\models\openaudio-s1-mini

# Endpoint HTTP de Fish (lo usa el TTS cliente)
FISH_HOST=127.0.0.1
FISH_PORT=8080
FISH_TTS_HTTP=http://127.0.0.1:8080/v1/tts

# Config del decoder de Fish Speech
FISH_DECODER_CONFIG=modded_dac_vq

# Tiempo máximo de arranque (segundos)
FISH_START_TIMEOUT=360

# ---- Límite de VRAM (recomendado para tu 3080 10GB) ----
# Nota: con 3.5GB vimos OOM en el decoder; usa ~5.0GB.
FISH_CUDA_MAX_GB=6.5
FISH_CUDA_VERBOSE=1

# Asignador CUDA (Windows: NO usar expandable_segments)
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32,garbage_collection_threshold:0.7

# Fijar la GPU a usar
CUDA_VISIBLE_DEVICES=0

# -------------------------------------------------------
# Voz fija (referencia local) 
# -------------------------------------------------------
FISH_REF_WAV=G:\Documentos G\Ing. Sotware\ExperimentosPy\IA_VtuberMain\IA_Vtuber\services\tts\reference\casiopy\CasiopyVoz-muestraWAV.wav
FISH_REF_TXT=Oh, con que te quedó dudas sobre Mochi. Bien te concederé un desvío de nuestras tareas en mano, ya que lo pediste de forma tan... amable y tierna. Mochi fue un regalo de mis padres hace tantísimos años atrás. Un regalo de parte de los dos, aunque la balanza de entregas se decanta más hacia el lado de... mi madre.
FISH_REF_ID=casiopy-fixed
FISH_USE_MEMORY_CACHE=on

