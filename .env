# ---- Otros servicios (tal cual los tienes) ----
GATEWAY_HTTP=http://127.0.0.1:8765
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_MODEL=gemma3

# ---- Fish Speech: rutas (ajusta si cambian) ----
FISH_REPO=G:\Documentos G\Ing. Sotware\ExperimentosPy\Fish-audio\fish-speech
FISH_VENV_PY=G:\Documentos G\Ing. Sotware\ExperimentosPy\Fish-audio\fish-speech\.fs\Scripts\python.exe
FISH_CKPT=G:\Documentos G\Ing. Sotware\ExperimentosPy\IA_VtuberMain\IA_Vtuber\services\tts\models\openaudio-s1-mini

# Endpoint HTTP de Fish (lo usa el TTS cliente)
FISH_HOST=127.0.0.1
FISH_PORT=8080
FISH_TTS_HTTP=http://127.0.0.1:8080/v1/tts

# Config del decoder de Fish Speech
FISH_DECODER_CONFIG=modded_dac_vq

# Tiempo máximo de arranque (segundos)
FISH_START_TIMEOUT=360

# ---- Límite de VRAM (recomendado para tu 3080 10GB) ----
# Nota: con 3.5GB vimos OOM en el decoder; usa ~5.0GB.
FISH_CUDA_MAX_GB=5.0
FISH_CUDA_VERBOSE=1

# Asignador CUDA (Windows: NO usar expandable_segments)
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64,garbage_collection_threshold:0.8

# Fijar la GPU a usar
CUDA_VISIBLE_DEVICES=0
