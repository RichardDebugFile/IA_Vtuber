# ğŸ§  Casiopy Memory Service

Sistema de memoria persistente y evolutiva para Casiopy VTuber AI.

## ğŸ“‹ CaracterÃ­sticas

- **Capa 0 (Core Memory)**: Memoria inmutable - identidad, gustos, personalidad permanente
- **Capa 1 (LoRA Personality)**: Entrenamiento de personalidad estÃ¡tica con dataset natural
- **ğŸ†• Training Dashboard**: Interfaz web para monitorear entrenamiento en tiempo real
- **Almacenamiento de interacciones**: Captura completa de conversaciones para anÃ¡lisis
- **Sistema de calidad**: Scoring automÃ¡tico para determinar quÃ© guardar
- **Backups automÃ¡ticos**: Multi-nivel (horario, diario, semanal)
- **ExportaciÃ³n para fine-tuning**: Formatos compatibles con Unsloth/Hermes-3
- **API RESTful**: FastAPI con documentaciÃ³n automÃ¡tica

---

## âš¡ Inicio RÃ¡pido - Training Dashboard

**Â¿Quieres entrenar la personalidad de Casiopy?** El sistema estÃ¡ completamente configurado:

1. **Instalar dependencias:**
   ```bash
   cd frontend
   pip install -r requirements.txt
   ```

2. **Iniciar dashboard:**
   ```bash
   start_dashboard.bat  # Windows
   # o
   python app.py
   ```

3. **Abrir en navegador:** http://localhost:5000

ğŸ“– **GuÃ­a completa:** [TRAINING_SETUP_COMPLETE.md](TRAINING_SETUP_COMPLETE.md)

---

## ğŸ—ï¸ Arquitectura

```
Core Memory (PostgreSQL)
    â†“
Interactions Storage
    â†“
Quality Scoring
    â†“
Training Export
    â†“
LoRA Fine-tuning (Unsloth)
```

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Configurar variables de entorno

```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

### 2. Iniciar PostgreSQL con Docker

```bash
docker-compose up -d
```

Esto iniciarÃ¡:
- PostgreSQL 16 con pgvector (puerto 8821)
- Backup automÃ¡tico cada hora

### 3. Instalar dependencias Python

```bash
pip install -r requirements.txt
```

### 4. Iniciar el servicio

```bash
cd src
python main.py
```

El servicio estarÃ¡ disponible en: `http://localhost:8820`

## ğŸ“š DocumentaciÃ³n API

Una vez iniciado el servicio, accede a:

- **Swagger UI**: http://localhost:8820/docs
- **ReDoc**: http://localhost:8820/redoc

## ğŸ”§ Endpoints Principales

### Core Memory (Capa 0)

```bash
# Obtener toda la core memory
GET /core-memory

# Obtener por categorÃ­a
GET /core-memory/{category}

# Generar system prompt
GET /core-memory/system-prompt/generate

# Agregar entrada
POST /core-memory
{
  "category": "like",
  "key": "language_rust",
  "value": "Rust es fascinante",
  "is_mutable": false
}
```

### Sessions & Interactions

```bash
# Crear sesiÃ³n
POST /sessions
{
  "user_id": "user123",
  "opt_out_training": false
}

# Almacenar interacciÃ³n
POST /interactions
{
  "session_id": "uuid-here",
  "input_text": "Hola Casiopy",
  "output_text": "*suspiro* Hola... quÃ© necesitas?",
  "input_emotion": "neutral",
  "output_emotion": "sarcastic"
}

# Finalizar sesiÃ³n
POST /sessions/{session_id}/end
```

### Training Data

```bash
# Obtener interacciones listas para entrenamiento
GET /interactions/training-ready?min_quality=0.6

# Actualizar quality score
PUT /interactions/{interaction_id}/quality
{
  "quality_score": 0.85
}
```

## ğŸ’¾ Sistema de Backups

### Backups AutomÃ¡ticos

El contenedor `memory-backup` realiza backups automÃ¡ticamente:
- **Cada hora**: Backup incremental
- **RetenciÃ³n**: 7 dÃ­as, 4 semanas, 6 meses

### Backups Manuales

```bash
# Backup diario
./backup_daily.sh

# Backup semanal completo
./backup_weekly.sh

# Restaurar desde backup
./restore_backup.sh ./backups/daily/memory_daily_YYYYMMDD_HHMMSS.dump
```

## ğŸ“Š Estructura de la Base de Datos

### Tablas Principales

1. **core_memory**: Memoria inmutable (Capa 0)
2. **sessions**: AgrupaciÃ³n de conversaciones
3. **interactions**: Cada input/output con embeddings
4. **topics**: Temas detectados automÃ¡ticamente
5. **feedback**: RetroalimentaciÃ³n del usuario
6. **training_exports**: Registro de exportaciones
7. **lora_versions**: Control de versiones de LoRA

## ğŸ§ª Testing

```bash
# Verificar que PostgreSQL estÃ¡ corriendo
docker ps | grep casiopy-memory-db

# Test de conexiÃ³n
curl http://localhost:8820/health

# Ver estadÃ­sticas
curl http://localhost:8820/stats
```

## ğŸ” Seguridad

- Las contraseÃ±as se almacenan en `.env` (no committear)
- AnonimizaciÃ³n de datos de usuario antes de export
- Soporte para opt-out de entrenamiento
- Backups encriptados (configurar en producciÃ³n)

## ğŸ“ Estructura del Proyecto

```
memory-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ database.py             # DB connection
â”‚   â”œâ”€â”€ core_memory.py          # Core Memory manager
â”‚   â””â”€â”€ interaction_manager.py  # Interactions manager
â”œâ”€â”€ init-scripts/
â”‚   â”œâ”€â”€ 01_init_schema.sql      # DB schema
â”‚   â””â”€â”€ 02_populate_core_memory.sql  # Initial data
â”œâ”€â”€ backups/                    # Backup storage
â”‚   â”œâ”€â”€ hourly/
â”‚   â”œâ”€â”€ daily/
â”‚   â”œâ”€â”€ weekly/
â”‚   â””â”€â”€ wal/
â”œâ”€â”€ exports/                    # Training exports
â”œâ”€â”€ lora_adapters/             # Trained LoRAs
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## ğŸ”„ Flujo de Trabajo

### 1. Captura de Interacciones

```python
# Desde el Conversation Service
response = httpx.post("http://localhost:8820/interactions", json={
    "session_id": session_id,
    "input_text": user_input,
    "output_text": casiopy_response,
    "input_emotion": detected_emotion,
    "output_emotion": "sarcastic",
    "model_version": "hermes-3-week-05"
})
```

### 2. Procesamiento Semanal

```bash
# Exportar datos de la semana
GET /interactions/training-ready?min_quality=0.6

# Generar dataset para Unsloth
python scripts/export_training_data.py --format chatml --output ./exports/week_05.jsonl
```

### 3. Fine-tuning con Unsloth

Ver documentaciÃ³n en: `ia_docs/memory-service/MEMORIA_PERSONALIDAD.md`

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar puerto

Editar `.env`:
```
API_PORT=8820  # Puerto por defecto del Memory Service
```

### Habilitar debug SQL

Editar `src/database.py`:
```python
engine = create_async_engine(
    DATABASE_URL,
    echo=True,  # Ver todas las queries SQL
    ...
)
```

## ğŸ› Troubleshooting

### PostgreSQL no inicia

```bash
docker-compose logs memory-postgres
docker-compose down
docker-compose up -d
```

### Error de conexiÃ³n

Verificar que los puertos no estÃ©n en uso:
```bash
netstat -an | grep 8820  # API
netstat -an | grep 8821  # PostgreSQL
```

### Permisos de backup scripts

```bash
chmod +x backup_daily.sh
chmod +x backup_weekly.sh
chmod +x restore_backup.sh
```

## ğŸ“ˆ PrÃ³ximos Pasos

1. âœ… Setup inicial completo
2. âœ… API funcionando
3. âœ… Sistema de embeddings (sentence-transformers)
4. âœ… Scripts de exportaciÃ³n para training
5. âœ… Training pipeline con Unsloth
6. ğŸ”„ IntegraciÃ³n con Conversation Service
7. â³ ExportaciÃ³n automÃ¡tica semanal (cron job)

## ğŸ“ Training de LoRAs

Este servicio incluye un **sistema completo de entrenamiento multicapa** para crear y mantener la personalidad de Casiopy.

### ConfiguraciÃ³n RÃ¡pida

```bash
# Windows
setup_training.bat

# Linux/Mac
chmod +x setup_training.sh
./setup_training.sh
```

### Arquitectura de Capas

- **Capa 0** (PostgreSQL): Core Memory - identidad, gustos, amigos
- **Capa 1** (LoRA Static): Personalidad - sarcasmo, actitud (se entrena UNA vez)
- **Capa 2** (LoRA Dynamic): EpisÃ³dico - conversaciones semanales
- **Capa 3** (LoRA On-Demand): Habilidades tÃ©cnicas (opcional)

### Scripts de Training

```bash
cd scripts

# 1. Exportar datos
python export_training_data.py --type personality
python export_training_data.py --type episodic --week 5

# 2. Entrenar LoRAs
python train_personality_lora.py --dataset ../exports/personality/*.jsonl
python train_episodic_lora.py --dataset ../exports/episodic/*.jsonl --week 5

# 3. Desplegar a Ollama
python deploy_to_ollama.py --week 5

# 4. Validar (anti-lobotomÃ­a)
python test_personality.py --model casiopy:week05 --save-report
```

### DocumentaciÃ³n Completa

Ver [TRAINING_WORKFLOW.md](TRAINING_WORKFLOW.md) para el workflow completo paso a paso.

## ğŸ¤ IntegraciÃ³n con Sistema Quimera

Este servicio es parte del **Sistema Quimera** y se integra con:

- **Conversation Service**: EnvÃ­a interacciones
- **Gateway**: Routing de requests
- **Monitoring**: MÃ©tricas y logs

Para mÃ¡s informaciÃ³n, ver: `ia_docs/memory-service/ARQUITECTURA_MEMORIA.md`

## ğŸ“ Notas Importantes

- **NUNCA** modificar core_memory con `is_mutable=false`
- **SIEMPRE** hacer backup antes de cambios mayores
- **VERIFICAR** opt-out antes de exportar para training
- **PERSONALIZAR** `02_populate_core_memory.sql` con informaciÃ³n real

## ğŸ†˜ Soporte

Para reportar issues o contribuir:
1. Revisar logs en `./logs/memory_service.log`
2. Verificar estado de DB con `/stats` endpoint
3. Consultar documentaciÃ³n completa en `ia_docs/memory-service/`
